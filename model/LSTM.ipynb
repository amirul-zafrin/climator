{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbaIGwQQWJCi",
        "outputId": "93cbaff0-c96a-491f-bd95-de60d59406f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 26 07:37:13 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P0    30W /  70W |   3108MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "GYVFXEgeWilZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8szY6XLEV4aV"
      },
      "outputs": [],
      "source": [
        "class SequenceDataset(Dataset):\n",
        "    def __init__(self, data, sequence_length=5):\n",
        "      self.data = data\n",
        "      self.data = torch.from_numpy(data).float().view(-1)\n",
        "      self.sequence_length = sequence_length\n",
        "    \n",
        "    def __len__(self):\n",
        "      return len(self.data) - self.sequence_length-1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      return self.data[idx : idx+self.sequence_length], self.data[idx+self.sequence_length]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data\n",
        "data = pd.read_csv('temperature_filtered.csv', header=None)\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df[\"unix\"] = data[2]\n",
        "df[\"temp\"] = data[6]\n",
        "\n",
        "train_size = int(len(df) * 0.8)\n",
        "\n",
        "train_df, test_df = df[:train_size], df[train_size+1:]\n",
        "print(f\"train: {train_df.shape}; test: {test_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-ToDyKxWT7n",
        "outputId": "1cd6c948-3d53-4cd5-9563-2df2b1dcbe03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: (268104, 2); test: (67026, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = data[6]\n",
        "df1 = df1.dropna()"
      ],
      "metadata": {
        "id": "vhuCAX_OXIOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = MinMaxScaler(feature_range=(0,1))\n",
        "df1 = scalar.fit_transform(np.array(df1).reshape(-1,1))"
      ],
      "metadata": {
        "id": "_5zY6shCZamQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_size = int(len(df1)*0.75)\n",
        "train_data, test_data = df1[0:training_size,:],df1[training_size:,:1]"
      ],
      "metadata": {
        "id": "tKSXc1ROaIZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 100\n",
        "train_dataset = SequenceDataset(train_data, sequence_length)\n",
        "test_dataset = SequenceDataset(test_data, sequence_length)"
      ],
      "metadata": {
        "id": "WswI-RTjbTIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_dataloader = DataLoader(train_dataset, batch_size, drop_last=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size, drop_last=True)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "82X9CEdSb5yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM_model(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_size, num_layers):\n",
        "    super(LSTM_model, self).__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.input_size = input_dim\n",
        "    self.hidden_size = hidden_size\n",
        "    self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_size, num_layers=num_layers)\n",
        "    self.dense1 = nn.Linear(hidden_size,32)\n",
        "    self.dense2 = nn.Linear(32,1)\n",
        "\n",
        "  def forward(self,x,hn,cn):\n",
        "    out , (hn,cn) = self.lstm(x, (hn,cn))\n",
        "    out = self.dense1(out[-1])\n",
        "    final_out = self.dense2(out)\n",
        "    return final_out,hn,cn\n",
        "\n",
        "  def predict(self,x):\n",
        "    hn, cn = self.init()\n",
        "    final_out = self.dense(out[-1])\n",
        "    return final_out\n",
        "\n",
        "  def init(self):\n",
        "    h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "    c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "    return h0,c0\n"
      ],
      "metadata": {
        "id": "DBaF1o_rdNF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 1\n",
        "hidden_size = 50\n",
        "num_layers = 3\n",
        "\n",
        "model = LSTM_model(input_dim, hidden_size, num_layers).to(device)\n"
      ],
      "metadata": {
        "id": "QyQObvcKekjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "botXGbGoeyJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader):\n",
        "  hn, cn = model.init()\n",
        "  model.train()\n",
        "  for batch, item in enumerate(dataloader):\n",
        "    x,y = item\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    out, hn, cn = model(x.reshape(sequence_length, batch_size,1),hn,cn)\n",
        "    loss = criterion(out.reshape(batch_size),y)\n",
        "    hn = hn.detach()\n",
        "    cn = cn.detach()\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch == len(dataloader)-1:\n",
        "      loss = loss.item()\n",
        "      print(f\"Train Loss: {loss}\")"
      ],
      "metadata": {
        "id": "itonHrcTe-u6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader):\n",
        "  hn, cn = model.init()\n",
        "  model.eval()\n",
        "  for batch, item in enumerate(dataloader):\n",
        "    x,y = item\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    out, hn, cn = model(x.reshape(sequence_length,batch_size,1),hn,cn)\n",
        "    loss = criterion(out.reshape(batch_size),y)\n",
        "\n",
        "    if batch == len(dataloader)-1:\n",
        "      loss = loss.item()\n",
        "      print(f\"Test Loss: {loss}\")"
      ],
      "metadata": {
        "id": "QO5SKLOKfyVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print(f\"Epoch: {epoch}/{epochs}\")\n",
        "  train(train_dataloader)\n",
        "  test(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB13LJzKgYw6",
        "outputId": "b9adaef1-3967-43dd-8782-47d58a461367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/10\n",
            "Train Loss: 0.003728205105289817\n",
            "Test Loss: 0.005388734396547079\n",
            "Epoch: 1/10\n",
            "Train Loss: 0.0037262276746332645\n",
            "Test Loss: 0.005392014980316162\n",
            "Epoch: 2/10\n",
            "Train Loss: 0.0037236418575048447\n",
            "Test Loss: 0.005398253910243511\n",
            "Epoch: 3/10\n",
            "Train Loss: 0.0037281804252415895\n",
            "Test Loss: 0.0054739098995924\n",
            "Epoch: 4/10\n",
            "Train Loss: 0.003721444169059396\n",
            "Test Loss: 0.005405885633081198\n",
            "Epoch: 5/10\n",
            "Train Loss: 0.0037166145630180836\n",
            "Test Loss: 0.005429779179394245\n",
            "Epoch: 6/10\n",
            "Train Loss: 0.003707971889525652\n",
            "Test Loss: 0.005377006717026234\n",
            "Epoch: 7/10\n",
            "Train Loss: 0.0038196758832782507\n",
            "Test Loss: 0.005251774098724127\n",
            "Epoch: 8/10\n",
            "Train Loss: 0.0039138710126280785\n",
            "Test Loss: 0.005272689275443554\n",
            "Epoch: 9/10\n",
            "Train Loss: 0.0033833803609013557\n",
            "Test Loss: 0.004746627993881702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "def calculate_metrics(data_loader):\n",
        "  pred_arr = []\n",
        "  y_arr = []\n",
        "  with torch.no_grad():\n",
        "    hn, cn = model.init()\n",
        "    for batch, item in enumerate(data_loader):\n",
        "      x, y = item\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      x = x.view(sequence_length,batch_size,1)\n",
        "      pred = model(x,hn,cn)[0]\n",
        "      pred = scalar.inverse_transform(pred.detach().cpu().numpy()).reshape(-1)\n",
        "      y = scalar.inverse_transform(y.detach().cpu().numpy().reshape(1,-1)).reshape(-1)\n",
        "      pred_arr = pred_arr + list(pred)\n",
        "      y_arr = y_arr + list(y)\n",
        "    return math.sqrt(mean_squared_error(y_arr,pred_arr))"
      ],
      "metadata": {
        "id": "AxVla5RkguuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training mse loss: {calculate_metrics(train_dataloader)}\")\n",
        "print(f\"Test mse loss: {calculate_metrics(test_dataloader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF03UKlJkZrd",
        "outputId": "eb8fb786-2234-45b0-f28e-fbabf00d83de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training mse loss: 2.2831116487502707\n",
            "Test mse loss: 1.699484758273376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(model.state_dict(), \"LSTM_model\")"
      ],
      "metadata": {
        "id": "kRNBsAiPlZlB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}